\documentclass{stylesheet}

\usepackage{color}
\usepackage{url}
\usepackage{enumerate}
\usepackage{verbatim}
\usepackage[english]{babel}%spell check
\usepackage[colorinlistoftodos]{todonotes}%todo
\usepackage{etoolbox}%Remove the ugly copyright from the template :-)
\makeatletter%Remove the ugly copyright from the template :-)
\patchcmd{\maketitle}{\@copyrightspace}{}{}{}%Remove the ugly copyright from the template :-)
\makeatother%Remove the ugly copyright from the template :-)

\usepackage[nameinlink,capitalise]{cleveref}

\begin{document}
\title{Cloud Computing}

\numberofauthors{5} 
\author{
% 1st. author
\alignauthor
Christos Froussios\\
	\affaddr{4322754}\\
	\email{C.Froussios @student.tudelft.nl}
% 2nd. author
\alignauthor
Richard van Heest\\
	\affaddr{4086570}\\
	\email{A.W.M.vanHeest @student.tudelft.nl}
\and
% Alex
\alignauthor
Alexandru Iosup\\
	\affaddr{Course instructor}
	\email{A.Iosup@tudelft.nl}
% Dick
\alignauthor
Dick Epema\\
	\affaddr{Course instructor}
	\email{D.H.J.Epema@tudelft.nl}
% Alexey
\alignauthor
Alexey Ilyushkin\\
	\affaddr{Teaching Assistant}
	\email{A.S.Ilyushkin@tudelft.nl}
}

\maketitle

\begin{abstract}
In this report we describe our findings of 1 month of research in the area of cloud computing. We build a small prototype of a IaaS-based application that does image processing using the Amazon Web Services (AWS) EC2 cloud platform. To solve issues like scalability and load balancing, we developed and compared several policies. The main features of this prototype are automation, scalability, load balancing, reliability and monitoring. Furthermore we measured the performance of the system by applying metrics like \textcolor{red}{TODO \ldots}
\end{abstract}

\section{Introduction}
\textcolor{red}{+ title + abstract (150 words) = 1 page}

Cloud computing has gained an increasing interest in the last couple of years. In contrast to the era of grid computing, not only the academic world is interested in this new way of performing large scale computations, but also companies do so. The most logic explanation for this shift of interest is that computer grids are expensive to invest in for a company which may not use the required hardware constantly, whereas in cloud computing that company would lease the required machines, scale up or down if appropriate and only get charged for the hours between leasing and releasing.

We distinguish three types of cloud computing:
\begin{description}
	\item[Software as a Service (SaaS)] applications such as Google Drive, Dropbox, Gmail, Yahoo mail and Facebook.
	\item[Platform as a Service (PaaS)] the computing platforms which typically include operating systems, programming language execution environments, databases and web servers. Examples of this are Apache Hadoop, Google App Engine, Windows Azure and Amazon Web Services Elastic Beanstalk.
	\item[Infrastructure as a Service (IaaS)] the computing infrastructure, physical or (more often) virtual machines and other resources like virtual-machine disk image libraries, block and file-based storage, firewalls, load balancers, IP addresses and virtual local area networks. The most prominent products in this category are Windows Azure, Google Compute Engine and Amazon EC2.
\end{description}

In this report we will focus on IaaS cloud computing especially, as requested to investigate by WantCloud BV. We will look into the advantages and disadvantages of IaaS by implementing a small prototype for a potential future system. The main features of this prototype can be summarized as:
\begin{description}
	\item[Automation] working as much as possible independently from any human interaction
	\item[Elasticity (auto-scaling)] leasing and releasing machines from a resource pool as workloads change over time
	\item[Performance (load balancing)] allocating workloads to machines from the resource pool in such a way that the machines are used as effective as possible.
	\item[Reliability] building in a fair amount of fault tolerance
	\item[Monitoring] observing and recording the status of the system as well as measuring the performance of the system and its components by applying various metrics.
	\item[TODO] \textbf{\textit{\underline{additional features???}}}
\end{description}

The prototype to be implemented will be an application that receives pictures from an external source (for example a web form where users can submit their pictures), performs some operations on them and returns the processed pictures. These operations may vary from lightweight operations such as a flip of the picture to heavier operations like Fourier transform.

The application is set up in such a way that all pictures are received at a head node, which allocates them to one of the worker node in its resource pool and leases new machines or releases idle machines when appropriate. We present and compare multiple policies for these problems.

This report is structured as follows: first we will discuss the background of the application in \cref{sec:background}. What does it do in detail? What are its requirements and features? This is followed by the system design in \cref{sec:design}, where we focus on the internal workings of the application as well as several policies for both the processes of allocation and leasing/releasing nodes. We evaluate the application in \cref{sec:experiments} by applying several metrics. Finally we close the report with a discussion (\cref{sec:discussion}) and the conclusion (\cref{sec:conclusion}). In \cref{app:time} an overview of spent time is provided.

\textcolor{red}{TODO existing systems and/or tools}

\section{Background of the application}
\label{sec:background}
\textcolor{red}{0.5 page: describe application (1 paragraph) + requirements (1-3 paragraphs)}

The application we build over the course of several weeks is a prototype of a more generic cloud centered solution where tasks come in at the head node and are distributed over a number of worker nodes. In this particular application we choose to take image processing as the workload. Pictures that are received by an arbitrary worker are modified by applying a number of operations, combining them afterwards. Notice that this approach has a high potential for the task being split into subtasks and make it into a MapReduce process. However, to make things not overly complicated in this prototype, we consider one picture as one \textit{undividable} task, which is executed on a single node.

The requirements of our application can be split up into 5 tiers. First of all, the application needs to run without human intervention as much as possible. We fulfilled this requirement by only having to start the head node application and providing pictures over the course of the runtime. Besides these 2 acts, the head node automatically decides when to lease and release worker nodes, to which worker an incoming task is sent and to where a completed task needs to be returned. On the other hand, the worker nodes automatically receive tasks, process them as soon as they possible can and make sure they send back the result to the head node.

A second tier holds the elasticity (or scalability) of the system, which is determined by the head node. Elasticity in the context of cloud computing describes to which degree the system is able to grow and shrink its number of resources. In this case, these resources are the worker nodes, which can be leased or released. When the system gets overloaded with tasks, it might be a good idea to lease more workers. On the other hand, when there are hardly any tasks in the system, it is useless to have a large number of idle workers, since they are being payed for all that time. Ideally you want to predict when the system will have a peak moment in the number of tasks and when it will get more quiet. For this, machine learning is a nice path to follow. This however is not part of this project.

Besides elasticity, load balancing is another topic of interest in cloud computing. When the head node receives a task, it needs to decide where it should be executed. Does it prefer certain workers, will it be assigned randomly or is there a better way to schedule a task. In this the head node might look at the size of the task, the length of the queue of each available worker or any other measurable property of the task and the workers.

The fourth tier is the reliability of the system. As the application is mostly autonomous, it also needs to be able to recover itself from failure. A failure might be losing connection between the head node and one or more workers, crashing the head or a worker, IO failure, etc. For this project we make the assumption that the head node never crashes and \textcolor{red}{@Chris complete this when we implemented this}.

Finally, a system isn't a good system without a monitoring module. To make decisions in the other tiers (especially elasticity and load balancing), we need to supply it with proper data, for example the length of each worker's queue, the number of incoming tasks in the system, etc. Also for the research part of this project the monitoring module is used. This is used to gain the results in \cref{sec:experiments}.

\section{System Design}
\label{sec:design}
\textcolor{red}{1.5 pages}

The application we present here can be seen as a prototype for a typical cloud centric work flow, where a user sends workloads to a head node, which distributes it over one or more workers (depending on whether the workloads are splittable into subtasks). Once the workload is processed, a result is send back to the head node, which forwards this result to the appropriate user. Based on the workloads, the head node needs to decide to which worker a workload is allocated and whether or not to lease or release workers, for which it uses certain policies.

In this section we will discuss the system's architecture, work flow, communication between client, head node and workers, as well as the policies that are used in scaling and load balancing. \textcolor{red}{Furthermore we will describe some additional features that are in the system.}

\subsection{Resource Management}
\label{subsec:resourceManagement}
\textcolor{red}{Description of the design of the system + provisioning, allocation, reliability and monitoring}

In order to understand the system's architecture and work flow, let's follow a workload as it works its way through the system. We refer to \cref{fig:headnode} and \cref{fig:worker} for an overview of the architecture.

The user who sends this workload will sign in to the head node via a socket connection. This connection request comes in at the \texttt{ClientReception}, which creates a \texttt{ClientHandle} for workloads to be received. From this point on, the user interacts directly with its own \texttt{ClientHandle} in the head node. When this receives a workload, it makes a local copy of the workload and adds it to the \texttt{TaskQueue}. This is where all workloads come together while waiting to be processed. It should be noted that (for reasons explained later) the \texttt{TaskQueue} is a double-ended queue, meaning that tasks not only can be pushed at the end of the queue but also at the beginning.

\begin{figure*}
	\centering
	\includegraphics[width=\textwidth]{Architecture_head.png}
	\caption{Architecture in the head node}
	\label{fig:headnode}
\end{figure*}

\begin{figure*}
	\centering
	\includegraphics[width=0.8 \linewidth]{Architecture_worker.png}
	\caption{Architecture in a worker}
	\label{fig:worker}
\end{figure*}

The \texttt{Monitor} continuously samples the current state of the head node. For this reason, it also knows that the workload is queued. Based on the total workload in the queue (and other metrics and policies that are explained later), it decides whether or not to lease extra workers. When extra workers are needed, the \texttt{Monitor} makes a call to the Cloud Service to request a new machine.

The \texttt{WorkerReception} waits for this machine to contact the head node. Once the socket connection is established, a \texttt{WorkerHandle} is created and stored in the head node, via which all future communication with the newly leased machine will take place. The first communication is the worker who introduces itself and tell how many cores it has. This information is stored in the \texttt{WorkerHandle} for later use. Once this formal procedure is over, the new worker will wait for the first workloads to come in.

Besides coordinating the leasing of workers, the \texttt{Monitor} is also responsible for cleaning up workers that are not needed anymore. This is done based on metrics and policies that will be discussed later. When it decides to release a worker, the corresponding {\verb WorkerHandle } will be flagged as being set for decommission. After that, no more tasks can be scheduled on that worker; it will only finish its currently scheduled tasks, after which is is released.

The \texttt{Scheduler} takes workloads out of the \texttt{TaskQueue} and decides on which workers they will be processed. This subsystem takes all tasks out of the queue and collects all eligible workers (the ones that are not flagged for decommission). Based on a predefined policy, an allocation plan is made where tasks are assigned to certain workers. It is possible in some policies that not all tasks can be scheduled at once. For that reason, not only the allocation plan is returned by the policies, but also a list of not yet scheduled tasks. The latter will be put back on top of the queue, so that they are the first to be scheduled again next time. The tasks that were in the allocation plan will get assigned to the appropriate workers by sending their workloads over the previously established socket connection. In the case the connection failed in the meantime, the task is put back in the queue as well to be rescheduled.

When a task is allocated to a certain worker, its workload will be send over there via the socket connection. At the worker side, it is received by the \texttt{Input} subsystem, which puts it in the \texttt{InputQueue} for it to be processed. When the \texttt{Processing} subsystem is finished with the previous task, it will take the workload out of the queue and performs the actual processing. After that is finished, the result is put into the \texttt{OutputQueue}, from where it is send back to the head node by the \texttt{Output} subsystem.

At the head node, the result is received over the socket  by the \texttt{WorkerHandle} which removes the corresponding task from the list of currently processed jobs and adds the result to the \texttt{ProcessedQueue}. There it waits until the \texttt{Responder} takes it out and sends it back to the user.

\subsection{Architectural improvements}
The architecture described above is what the application currently looks like. However, this does not fully satisfy the redundancy requirement. This is due to this project's deadline. In the following we describe what to change in and add to the architecture to fully support this requirement.

\textcolor{red}{@Chris, describe what happens when a worker fails during execution. How is this detected and how is the head node responding to that? Also mention that we assume the head node to not fail.}

\subsection{System policies}
\label{subsec:policies}
\textcolor{red}{Description of the supported (future work) and used policies.}

When it comes to scheduling tasks or leasing and releasing workers, the approach can influence the performance of the whole system. In this section we discuss the different policies we created for both scheduling, leasing and releasing.

\subsubsection*{Scheduling policies}
Every scheduling policy implementation receives a list of tasks to be scheduled as well as a collection of eligible workers and has to return both an allocation plan and a list of unscheduled tasks. We first present some simple policies, followed by some more sophisticated policies that are all scheduling all provided tasks. After that, we modify the latter policies to only schedule some of the tasks while rejecting others.

A very basic scheduling policy, the \texttt{RoundRobinScheduler}, does not need any knowledge about the workers or the tasks. It allocates the tasks by iterating over the collection of workers. It treads every worker and every task in an equal way, giving no priority to any of the tasks and not regarding the length of the queue of a certain worker.

A modification of this policy would be to not iterate over the collection of workers but instead allocate the tasks randomly to certain workers, hence the name \texttt{RandomScheduler}. This might cause an unbalance in the distribution of tasks on a single scheduler run, but given simple statistical methods and theorems it will ultimately give a more balanced solution in the long run.

The previous policies might be used when the scheduler for particular reasons is not allowed or able to know the current state of the workers or the contents of the tasks. However, when this restriction is not there, an obvious more sophisticated policy is the \texttt{QueueLengthScheduler}, which makes the allocation decision based on the number of tasks that are already present in that worker. The worker with the least amount of tasks will be the one to execute the task at hand. This however asks either for a lot of communication with each of the workers to check their status or a good bookkeeping solution in the head node. The decision for this trade-off can be based on the amount of computer memory versus the speed of the communication. Also this policy assumes that all tasks are of equal processing length, which is more than often not the case.

A policy that takes this processing length into account is the \texttt{QueuePixelScheduler}. This is a somewhat special policy for our case of image processing that follows from the way our image processing works as well as from some initial experimental work, which is described in \textcolor{red}{refer to the experiments} and can be summarized by the conclusion that the number of pixels in a picture is proportional to the processing time of that picture. Therefore this policy modifies the \texttt{QueueLengthScheduler} by taking into account \textit{the number of pixels} rather than \textit{the number of tasks} in a particular worker.

Until this point all policies have allocated all the provided tasks to eligible workers. We defined the eligibility of a worker as not being flagged for decommission. However, when we extend this definition by following the philosophy that a worker should only have $2n$ tasks in its system ($n$ tasks in process and $n$ tasks in its queue, where $n$ is the number of processors in that worker node), we end up with a smaller set of workers that are available to receive new tasks. This means that the tasks stay in the head node as long as possible, rather than waiting in a queue in the worker node, which has the advantage that the worker can focus more of its time on processing the tasks rather then being busy with receiving tasks in its queue. Therefore the internal memory of the worker nodes can be used more for the execution of the tasks rather than storing dozens of next jobs. Besides that, using this type of policies makes the system easier to recover from a failing worker, since there are only two tasks in that worker that need to be rescheduled. We applied this paradigm to the \texttt{QueueLengthScheduler} and the \texttt{QueuePixelScheduler} and used this in the experiments presented in \cref{sec:experiments}.

\subsubsection*{Leasing and releasing policies}
\textcolor{red}{@Chris, can you write this?}

\subsection{Additional System Features}
\label{subsec:additionalFeatures}
\textcolor{red}{@Chris, Additional features: can you check which ones we have to write about?}
\ldots
\subsubsection{Feature 1}
\ldots
\subsubsection{Feature 2}
\ldots

\section{Experiments}
\label{sec:experiments}
\textcolor{red}{1.5 pages}
\subsection{Experimental setup}
\label{subsec:setup}
\textcolor{red}{Working environment (EC2), general workload and monitoring tools and other libraries}

\subsection{Experimental results}
\label{subsec:results}
\textcolor{red}{Description of the experiments conducted to analyze each system feature, analyze them and describe the workload, present the operation of the system and analyze the results. See assignment}

\section{Discussion}
\label{sec:discussion}
\textcolor{red}{1 page - main findings, tradeoffs inherent in the design of cloud-computing-based applications.}

\section{Conclusion}
\label{sec:conclusion}
\textcolor{red}{\ldots}

\bibliographystyle{abbrv}
\bibliography{references}

\appendix
\section{Time sheet}
\label{app:time}
\textcolor{red}{table with time spend}
\end{document}